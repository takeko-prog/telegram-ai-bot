import os
import random
import requests
import google.generativeai as genai

# Environment Variables
BOT_TOKEN = os.environ.get("BOT_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# Gemini Configuration
genai.configure(api_key=GEMINI_API_KEY)

# Model á€”á€¬á€™á€Šá€ºá€€á€­á€¯ á€¡á€á€­á€¡á€€á€» á€•á€¼á€”á€ºá€•á€¼á€„á€ºá€‘á€¬á€¸á€•á€«á€á€šá€º
model = genai.GenerativeModel('gemini-1.5-flash')

IDEAS = [
    "Your phone isnâ€™t spying on you â€” but this is worse",
    "Why free apps are secretly more expensive than paid ones",
    "This setting controls your entire phone life",
    "The algorithm doesnâ€™t hate you â€” it ignores you",
    "Where your deleted photos actually go"
]

def generate_script(topic):
    prompt = f"Write a full video script about: {topic}. Include Hook, Body, and Outro."
    try:
        # Generation config á€‘á€Šá€·á€ºá€á€¼á€„á€ºá€¸á€–á€¼á€„á€·á€º á€•á€­á€¯á€á€±á€á€»á€¬á€…á€±á€•á€«á€á€šá€º
        response = model.generate_content(prompt)
        if response.text:
            return response.text
        else:
            return "AI returned an empty response."
    except Exception as e:
        return f"Script generation failed: {str(e)}"

# Random áƒ á€á€¯á€›á€½á€±á€¸á€™á€šá€º
selected_topics = random.sample(IDEAS, 3)

def send_telegram(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "Markdown"
    }
    r = requests.post(url, data=payload)
    return r.ok

for i, topic in enumerate(selected_topics, 1):
    script = generate_script(topic)
    final_text = f"ğŸ¬ *Video Idea {i}*\n\nTopic: {topic}\n\n{script}"
    
    # Message á€›á€¾á€Šá€ºá€œá€½á€”á€ºá€¸á€›á€„á€º (á€á€­á€¯á€·) Markdown error á€á€€á€ºá€›á€„á€º plain text á€”á€²á€· á€•á€¼á€”á€ºá€•á€­á€¯á€·á€™á€šá€º
    if not send_telegram(final_text):
        requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage", 
                      data={"chat_id": CHAT_ID, "text": final_text})
